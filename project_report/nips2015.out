\BOOKMARK [1][-]{section.1}{The Game of Go}{}% 1
\BOOKMARK [1][-]{section.2}{Prior Art}{}% 2
\BOOKMARK [2][-]{subsection.2.1}{Monte Carlo Tree Search}{section.2}% 3
\BOOKMARK [2][-]{subsection.2.2}{Deep Convolutional Neural Net}{section.2}% 4
\BOOKMARK [2][-]{subsection.2.3}{DCNN / Monte Carlo Hybrid}{section.2}% 5
\BOOKMARK [1][-]{section.3}{Deep Q Learning for solving Go}{}% 6
\BOOKMARK [2][-]{subsection.3.1}{Reinforcement Learning}{section.3}% 7
\BOOKMARK [2][-]{subsection.3.2}{DeepMind's Atari Agent}{section.3}% 8
\BOOKMARK [2][-]{subsection.3.3}{Testing DeepMind's approach on Go}{section.3}% 9
\BOOKMARK [1][-]{section.4}{Building an Opposing Player}{}% 10
\BOOKMARK [2][-]{subsection.4.1}{Clark \046 Storkey's trained DCNN model}{section.4}% 11
\BOOKMARK [2][-]{subsection.4.2}{Pachi/Michi}{section.4}% 12
\BOOKMARK [2][-]{subsection.4.3}{GnuGo}{section.4}% 13
\BOOKMARK [1][-]{section.5}{Experiments}{}% 14
\BOOKMARK [2][-]{subsection.5.1}{Input representation of the game}{section.5}% 15
\BOOKMARK [3][-]{subsubsection.5.1.1}{One channel representation}{subsection.5.1}% 16
\BOOKMARK [3][-]{subsubsection.5.1.2}{Three channel representation}{subsection.5.1}% 17
\BOOKMARK [3][-]{subsubsection.5.1.3}{Seven channel representation}{subsection.5.1}% 18
\BOOKMARK [2][-]{subsection.5.2}{Architecture of the convolution neural network}{section.5}% 19
\BOOKMARK [2][-]{subsection.5.3}{Parameters of Q Learning}{section.5}% 20
\BOOKMARK [2][-]{subsection.5.4}{Weight tying}{section.5}% 21
\BOOKMARK [2][-]{subsection.5.5}{Illegal Moves}{section.5}% 22
\BOOKMARK [1][-]{section.6}{Results}{}% 23
\BOOKMARK [1][-]{section.7}{Analysis and Future Work}{}% 24
